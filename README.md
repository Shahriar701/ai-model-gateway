# AI Model Gateway

ğŸš€ **Production-ready AI model gateway** with unified access to multiple LLM providers, authentication, rate limiting, MCP integration, and comprehensive monitoring.

## âœ¨ Features

- **ğŸ¤– Multi-Provider Support**: OpenAI, AWS Bedrock with intelligent routing
- **ğŸ” Authentication**: API key management with tiered access control  
- **âš¡ Rate Limiting**: Configurable limits per user tier
- **ğŸ’° Cost Optimization**: Real-time cost tracking and optimization
- **ğŸ›ï¸ MCP Integration**: Product search and e-commerce context injection
- **ğŸ“Š Observability**: Comprehensive logging, metrics, and tracing
- **ğŸ”„ Circuit Breakers**: Automatic failover and error handling
- **ğŸš¦ Request Batching**: Intelligent request optimization

## ğŸš€ Quick Start (5 Minutes)

```bash
# 1. Deploy the gateway
cd ai-model-gateway
./deploy-full.sh

# 2. Test it works
curl "https://your-api-gateway-url/health"
```

**That's it!** Your AI Model Gateway is running.

## ğŸ“‹ Complete Setup

For full configuration with OpenAI integration, API keys, and product data:

ğŸ‘‰ **[Follow the Complete Setup Instructions](./SETUP_INSTRUCTIONS.md)**

## ğŸ§ª Test Your Deployment

```bash
# Health check
curl "https://your-api-url/health"

# Test with API key
curl -X POST "https://your-api-url/api/v1/completions" \
  -H "Content-Type: application/json" \
  -H "X-API-Key: your-api-key" \
  -d '{"model":"gpt-3.5-turbo","messages":[{"role":"user","content":"Hello!"}]}'
```

## ğŸ—ï¸ Architecture

```
API Gateway â†’ Lambda Handler â†’ LLM Providers (OpenAI/Bedrock)
     â†“              â†“
DynamoDB Tables   Monitoring & Caching
```

## ğŸ“ Project Structure

**Essential Files:**
- `SETUP_INSTRUCTIONS.md` - Complete setup guide
- `deploy-full.sh` - Main deployment script  
- `bin/ai-model-gateway-deploy.ts` - CDK deployment configuration
- `src/` - Full TypeScript implementation (47 completed tasks)

## ğŸ¯ What's Deployed

âœ… **All 47 tasks completed** including:
- Authentication & API key management
- Rate limiting with multiple tiers
- OpenAI & Bedrock provider integration
- MCP product search integration  
- Circuit breakers & error handling
- Comprehensive monitoring & health checks
- Request caching & optimization
- Security logging & compliance

## ğŸ“ Support

1. Check `SETUP_INSTRUCTIONS.md` for detailed configuration
2. View Lambda logs: `aws logs tail /aws/lambda/your-function-name --follow`
3. Test health endpoints: `/health`, `/api/v1/health/detailed`

## ğŸ‰ Ready for Production

Your AI Model Gateway includes enterprise-grade features and is ready for production use with proper configuration following the setup instructions.

---

**Next Step**: Open `SETUP_INSTRUCTIONS.md` for complete configuration! ğŸš€